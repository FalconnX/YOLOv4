{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "YOLOv4_Falcon.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "PU-X5nJll51Q"
      ],
      "toc_visible": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HBHChnMDln22"
      },
      "source": [
        "## Import libraries"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yh0LMtyay0qh"
      },
      "source": [
        "import torch\n",
        "import torchvision\n",
        "from torch import nn\n",
        "import torch.nn.functional as F\n",
        "import math\n",
        "\n",
        "from PIL import ImageFile\n",
        "ImageFile.LOAD_TRUNCATED_IMAGES = True\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o_D12sTWzbQw"
      },
      "source": [
        "# !pip install -U git+https://github.com/albu/albumentations --no-cache-dir"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ktk5E4VLltNo"
      },
      "source": [
        "## Logic Blocks"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twktW678094r"
      },
      "source": [
        "@torch.jit.script\n",
        "def mish(input):\n",
        "    return input * torch.tanh(F.softplus(input))\n",
        "\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super().__init__()\n",
        "\n",
        "    def forward(self, input):\n",
        "        return mish(input)\n",
        "\n",
        "# Spatial Attention Module\n",
        "class SAM_Module(nn.Module):\n",
        "    def __init__(self, in_c):\n",
        "        super().__init__()\n",
        "        self.conv_1x1 = nn.Conv2d(in_channels=in_c, out_channels=1, kernel_size=1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        attention_feature = torch.sigmoid(self.conv_1x1(x)).expand_as(x)\n",
        "        SAM_output = attention_feature * x\n",
        "        return SAM_output"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wytqeMUKyUer"
      },
      "source": [
        "class CBM(nn.Module):\n",
        "  def __init__(self, in_channels, out_channels, kernel_size, stride=1, padding=0,bn=True ,act='mish'):\n",
        "    super(CBM,self).__init__()\n",
        "    self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
        "    if bn:\n",
        "      self.bn   = nn.BatchNorm2d(out_channels)\n",
        "    if act =='mish':\n",
        "      self.mish = Mish()\n",
        "    elif act == 'leakyrelu':\n",
        "      self.leakyrelu = nn.LeakyReLU()\n",
        "    elif act == 'relu':\n",
        "      self.relu = nn.ReLU()\n",
        "    # if attention:\n",
        "    #   self.attention_module = SAM_Module()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    if self.bn:\n",
        "      x = self.bn(x)\n",
        "    if hasattr(self,'mish'):\n",
        "      x = self.mish(x)\n",
        "    elif hasattr(self,'leakyrelu'):\n",
        "      x = self.leakyrelu(x)\n",
        "    elif hasattr(self,'relu'):\n",
        "      x = self.relu(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WKRhe_Xe4ECW"
      },
      "source": [
        "class ResNetUnit(nn.Module):\n",
        "  def __init__(self,in_c,out_c,bn=True,act='mish'): \n",
        "    super(ResNetUnit,self).__init__()\n",
        "    self.cbm_1x1 = CBM(in_c, in_c,1,stride=1,padding=0,bn=True,act='mish') \n",
        "    self.cbm_3x3 = CBM(in_c,out_c,3,stride=1,padding=1,bn=True,act='mish')\n",
        "  def forward(self,x):\n",
        "    skip_connection = x\n",
        "    x = self.cbm_1x1(x)\n",
        "    x = self.cbm_3x3(x)\n",
        "    x = skip_connection + x\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Rf589cIoKXR7"
      },
      "source": [
        "class CSP(nn.Module):\n",
        "    CSP_num=1\n",
        "    def __init__(self,in_c, num_resnet):\n",
        "        super(CSP,self).__init__()\n",
        "        self.in_c = in_c\n",
        "#         print(\"CSP in_c\",in_c)\n",
        "        self.num_resnet = num_resnet\n",
        "\n",
        "        self.cbm1_3x3 = CBM(in_c , in_c*2, 3, stride=2,padding=1,bn=True,act='mish')\n",
        "\n",
        "        self.cbm2_1x1 = CBM(in_c*2 , in_c, 1, stride=1,padding=0,bn=True,act='mish')\n",
        "\n",
        "        self.cbm3_1x1 = CBM(in_c*2 , in_c, 1, stride=1,padding=0,bn=True,act='mish')\n",
        "\n",
        "        self.cbm4_resnet = nn.Sequential()\n",
        "        for i in range(self.num_resnet):\n",
        "            self.cbm4_resnet.add_module('ResNetUnit_{}_from_{}_CSP{}'.format(i,num_resnet,CSP.CSP_num),ResNetUnit(in_c,in_c,bn=True,act='mish') )\n",
        "\n",
        "        self.cmb5_1x1 = CBM(in_c,in_c,1, stride=1,padding=0,bn=True,act='mish')\n",
        "\n",
        "        self.cmb6_1x1 = CBM(in_c*2,in_c*2,1, stride=1, padding=0, bn=True, act='mish')\n",
        "    \n",
        "\n",
        "    def forward(self,x):\n",
        "\n",
        "        inp = self.cbm1_3x3(x)\n",
        "\n",
        "        skip_connection = self.cbm2_1x1(inp) \n",
        "\n",
        "        x = self.cbm3_1x1(inp)\n",
        "        x = self.cbm4_resnet(x)\n",
        "        x = self.cmb5_1x1(x)\n",
        "\n",
        "        x = torch.cat([skip_connection,x],dim=1)\n",
        "\n",
        "        x = self.cmb6_1x1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1RmFBL0ADrV5"
      },
      "source": [
        "class first_CSP(nn.Module):\n",
        "    def __init__(self,in_c):\n",
        "        super(first_CSP,self).__init__()\n",
        "        self.cbm1_3x3 = CBM(in_c, in_c*2, 3, stride=2,padding=1,bn=True,act='mish')\n",
        "\n",
        "        self.cbm2_1x1 = CBM(in_c*2, in_c*2, 1, stride=1,padding=0,bn=True,act='mish')\n",
        "\n",
        "        self.cbm3_1x1 = CBM(in_c*2, in_c*2, 1, stride=1,padding=0,bn=True,act='mish')\n",
        "        self.cbm4_resnet = ResNetUnit(in_c*2, in_c*2, bn=True,act='mish') \n",
        "        self.cmb5_1x1 = CBM(in_c*2, in_c*2, 1, stride=1,padding=0,bn=True,act='mish')\n",
        "\n",
        "        self.cmb6_1x1 = CBM(in_c*4, in_c*2, 1, stride=1, padding=0, bn=True, act='mish')\n",
        "\n",
        "\n",
        "    def forward(self,x):\n",
        "        inpu = self.cbm1_3x3(x)\n",
        "\n",
        "        skip_connection = self.cbm2_1x1(inpu) \n",
        "        \n",
        "        x = self.cbm3_1x1(inpu) \n",
        "        x = self.cbm4_resnet(x)\n",
        "        x = self.cmb5_1x1(x)\n",
        "\n",
        "        x = torch.cat([skip_connection,x],dim=1)\n",
        "        x = self.cmb6_1x1(x)\n",
        "        return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fpUZYtIYzcjK"
      },
      "source": [
        "class SPP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(SPP,self).__init__()\n",
        "    self.maxpool_5x5   = nn.MaxPool2d(kernel_size= 5 , stride=1, padding=2)\n",
        "    self.maxpool_9x9   = nn.MaxPool2d(kernel_size= 9 , stride=1, padding=4)\n",
        "    self.maxpool_13x13 = nn.MaxPool2d(kernel_size=13 , stride=1, padding=6)\n",
        "  def forward(self,x):\n",
        "    skip_connection = x\n",
        "    out1 = self.maxpool_5x5(x)\n",
        "    out2 = self.maxpool_9x9(x)\n",
        "    out3 = self.maxpool_13x13(x)\n",
        "    x = torch.cat([skip_connection,out1,out2,out3],dim=1)\n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lO7aZ-3prcg1"
      },
      "source": [
        "class CBL(nn.Module):\n",
        "  def __init__(self, in_c, out_c, kernel_size, stride=1, padding=0,act='leakyrelu'):\n",
        "    super(CBL,self).__init__()\n",
        "    self.act  = act\n",
        "    self.conv = nn.Conv2d(in_c, out_c, kernel_size, stride, padding)  #Conv2d(in_channels, out_channels, kernel_size , stride, padding)\n",
        "    self.bn   = nn.BatchNorm2d(out_c)\n",
        "    self.leakyrelu = nn.LeakyReLU()\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv(x)\n",
        "    if (self.act != None):\n",
        "        x = self.bn(x)\n",
        "        x = self.leakyrelu(x)\n",
        "        \n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lyh2rkySuVh8"
      },
      "source": [
        "class CBLx5 (nn.Module):\n",
        "  def __init__(self, in_c):\n",
        "    super(CBLx5,self).__init__()\n",
        "    out_c = int(in_c/2)\n",
        "    self.conv1 = CBL(in_c, out_c, kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.conv2 = CBL(out_c, in_c, kernel_size=3, stride=1, padding=1,act='leakyrelu')\n",
        "    self.conv3 = CBL(in_c, out_c, kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.conv4 = CBL(out_c, in_c, kernel_size=3, stride=1, padding=1,act='leakyrelu')\n",
        "    self.conv5 = CBL(in_c, out_c, kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)\n",
        "    x = self.conv2(x)\n",
        "    x = self.conv3(x)\n",
        "    x = self.conv4(x)\n",
        "    x = self.conv5(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D5NfHh6-0-MX"
      },
      "source": [
        "class CBLx3_1(nn.Module):  #After BackBone\n",
        "  def __init__(self):\n",
        "    super(CBLx3_1,self).__init__()\n",
        "    self.conv_1x1_1 = CBL(in_c=1024, out_c=512,  kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.conv_3x3   = CBL(in_c=512,  out_c=1024, kernel_size=3, stride=1, padding=1,act='leakyrelu')\n",
        "    self.conv_1x1_2 = CBL(in_c=1024, out_c=512,  kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "  def forward(self,x):      #C =1024 (BackBone output)\n",
        "    x = self.conv_1x1_1(x)  #C = 512\n",
        "    x = self.conv_3x3(x)    #C = 1024\n",
        "    x = self.conv_1x1_2(x)  #C = 512\n",
        "    return x\n",
        "\n",
        "class CBLx3_2(nn.Module):  #After SPP\n",
        "  def __init__(self):\n",
        "    super(CBLx3_2,self).__init__()\n",
        "    self.conv_1x1_1 = CBL(in_c=2048, out_c=512,  kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.conv_3x3   = CBL(in_c=512,  out_c=1024, kernel_size=3, stride=1, padding=1,act='leakyrelu')\n",
        "    self.conv_1x1_2 = CBL(in_c=1024, out_c=512,  kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "  def forward(self,x):      #C = 2048 (BackBone output)\n",
        "    x = self.conv_1x1_1(x)  #C = 512\n",
        "    x = self.conv_3x3(x)    #C = 1024\n",
        "    x = self.conv_1x1_2(x)  #C = 512\n",
        "    return x   "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqmbMo3xRsGY"
      },
      "source": [
        "class FPN_Lateral_Connection(nn.Module):\n",
        "  def __init__(self,in_c,out_c):\n",
        "    super(FPN_Lateral_Connection,self).__init__()\n",
        "    self.in_c  = in_c \n",
        "    self.out_c = out_c\n",
        "    self.cbl_1x1_upsample = CBL(in_c, out_c, kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.upsample         = nn.Upsample(scale_factor=2, mode='nearest') \n",
        "    \n",
        "    self.cbl_1x1          = CBL(in_c, out_c, kernel_size=1, stride=1, padding=0,act='leakyrelu')\n",
        "    self.cblx5            = CBLx5(in_c=in_c)\n",
        "  def forward(self,top_x, x): \n",
        "    out1 = self.cbl_1x1_upsample(top_x)   \n",
        "    out1 = self.upsample(out1)            \n",
        "\n",
        "    out2 = self.cbl_1x1(x)                \n",
        "    \n",
        "    x = torch.cat([out1,out2],dim=1)\n",
        "\n",
        "\n",
        "    x = self.cblx5(x)                    \n",
        "    return x\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L_FZ9qw1kQ8f"
      },
      "source": [
        "class PAN_Lateral_Connection(nn.Module):\n",
        "  def __init__(self,out_c):\n",
        "    super(PAN_Lateral_Connection,self).__init__()\n",
        "    self.cbl_3x3 = CBL(int(out_c/2), out_c, kernel_size=3, stride=2, padding=1,act='leakyrelu')\n",
        "\n",
        "    self.cblx5 = CBLx5(in_c=out_c*2)\n",
        "  def forward(self,down_x,x):\n",
        "    out1 = self.cbl_3x3(down_x) \n",
        "\n",
        "    x = torch.cat([out1,x],dim=1)\n",
        "\n",
        "    x = self.cblx5(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PU-X5nJll51Q"
      },
      "source": [
        "## YOLO BackBone -> Neck -> Head"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZmjUgv0Yl8rn"
      },
      "source": [
        "class CSPDarknet53(nn.Module):\n",
        "  def __init__(self):\n",
        "    super().__init__()\n",
        "    self.conv1 = CBM(in_channels=3, out_channels=32, kernel_size=3, stride=1, padding=1 ,bn=True ,act='mish') \n",
        "\n",
        "    self.first_csp = first_CSP(in_c=32) \n",
        "    self.csp2      = CSP(in_c=64, num_resnet=2) \n",
        "    self.csp8      = CSP(in_c=128, num_resnet=2) \n",
        "    self.csp8_2    = CSP(in_c=256, num_resnet=2) \n",
        "    self.csp4      = CSP(in_c=512, num_resnet=2) \n",
        "    \n",
        "  def forward(self,x):\n",
        "    x = self.conv1(x)     \n",
        "    x = self.first_csp(x) \n",
        "    x = self.csp2(x)      \n",
        "    x_s = self.csp8(x)    \n",
        "    x_m = self.csp8_2(x_s)  \n",
        "    x_l = self.csp4(x_m)  \n",
        "    return x_s, x_m, x_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O-I6Yo3Y0oTA"
      },
      "source": [
        "class Neck(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Neck,self).__init__()\n",
        "    self.cblx3_1 = CBLx3_1() \n",
        "    self.spp     = SPP()     \n",
        "    self.cblx3_2 = CBLx3_2() \n",
        "\n",
        "    self.fpn_medium = FPN_Lateral_Connection(in_c=512,out_c=256)   \n",
        "    self.fpn_small  = FPN_Lateral_Connection(in_c=256,out_c=128)  \n",
        "\n",
        "    self.pan_medium = PAN_Lateral_Connection(out_c=256)  \n",
        "    self.pan_large  = PAN_Lateral_Connection(out_c=512)  \n",
        "\n",
        "  def forward(self,backbone):           \n",
        "    x_s,x_m,x_l = backbone\n",
        "    spp_x_l = self.cblx3_1(x_l)      \n",
        "    spp_x_l = self.spp(spp_x_l)         \n",
        "    spp_x_l = self.cblx3_2(spp_x_l)      \n",
        "\n",
        "    fpn_x_l = spp_x_l                            \n",
        "    fpn_x_m = self.fpn_medium(fpn_x_l, x_m)       \n",
        "    fpn_x_s = self.fpn_small (fpn_x_m, x_s)      \n",
        "\n",
        "    pan_x_s = fpn_x_s                             \n",
        "    pan_x_m = self.pan_medium(pan_x_s, fpn_x_m)   \n",
        "    pan_x_l = self.pan_large (pan_x_m, fpn_x_l)  \n",
        "\n",
        "    return pan_x_s, pan_x_m, pan_x_l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdOl2Wmk48TU"
      },
      "source": [
        "class YOLO_head(nn.Module):\n",
        "  def __init__(self, in_c, num_anchor, num_class):\n",
        "    super().__init__()\n",
        "    self.final_c = num_anchor * (5 + num_class)\n",
        "    self.cbl_3x3 = CBL(in_c , in_c*2       , kernel_size=3, stride=1, padding=1,act='leakyrelu')  \n",
        "    self.cbl_1x1 = CBL(in_c*2, self.final_c, kernel_size=1, stride=1, padding=0,act=None) \n",
        "  def forward(self,pan_x):\n",
        "    x = self.cbl_3x3(pan_x) \n",
        "    x = self.cbl_1x1(x)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "51dLZ_yiqbrt"
      },
      "source": [
        "## YOLO Layer"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "juQ9LDrGqfm4"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YqVtVpL0e52Q"
      },
      "source": [
        "'''\n",
        "Reference: https://github.com/eriklindernoren/PyTorch-YOLOv3/blob/47b7c912877ca69db35b8af3a38d6522681b3bb3/models.py#L106\n",
        "'''\n",
        "class YOLO_Layer(nn.Module):\n",
        "    def __init__(self,  anchors, num_classes, img_dim=608):\n",
        "        super(YOLO_Layer,self).__init__()\n",
        "\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.ignore_thres = 0.5\n",
        "        self.obj_scale = 1\n",
        "        self.noobj_scale = 100\n",
        "        self.metrics = {}\n",
        "        self.img_dim = img_dim\n",
        "        self.grid_size = 0\n",
        "        \n",
        "    def forward(self, x, targets=None):\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "\n",
        "        num_samples = x.size(0)\n",
        "        grid_size = x.size(2)\n",
        "\n",
        "        prediction = (\n",
        "            x.view(num_samples, self.num_anchors, 5 + self.num_classes , grid_size, grid_size)\n",
        "            .permute(0, 1, 3, 4, 2)\n",
        "            .contiguous()\n",
        "        )\n",
        "\n",
        "        x = torch.sigmoid(prediction[..., 0])  \n",
        "        y = torch.sigmoid(prediction[..., 1])  \n",
        "        w = prediction[..., 2]  \n",
        "        h = prediction[..., 3] \n",
        "        pred_conf = torch.sigmoid(prediction[..., 4]) \n",
        "        pred_cls = torch.sigmoid(prediction[..., 5:]) \n",
        "\n",
        "\n",
        "        self.compute_grid_offsets(grid_size, cuda=x.is_cuda)\n",
        "\n",
        "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
        "        pred_boxes[..., 0] = x + self.grid_x\n",
        "        pred_boxes[..., 1] = y + self.grid_y\n",
        "        pred_boxes[..., 2] = torch.exp(w) * self.anchor_w\n",
        "        pred_boxes[..., 3] = torch.exp(h) * self.anchor_h\n",
        "\n",
        "        # Output Shape = [ Batch_size, Total_YOLO_anchors , 5+num_class ]\n",
        "        output = torch.cat(\n",
        "            (\n",
        "                pred_boxes.view(num_samples, -1, 4) * self.stride,\n",
        "                pred_conf.view(num_samples, -1, 1),\n",
        "                pred_cls.view(num_samples, -1, self.num_classes),\n",
        "            ),\n",
        "            -1,\n",
        "        )\n",
        "\n",
        "        if targets is None:\n",
        "            return output, 0\n",
        "\n",
        "        iou, class_mask, obj_mask, noobj_mask, tx, ty, tw, th, tcls, tconf, target_boxes = self.build_targets(\n",
        "                pred_boxes=pred_boxes,\n",
        "                pred_cls=pred_cls,\n",
        "                target=targets,\n",
        "                anchors=self.scaled_anchors,\n",
        "                ignore_thres=self.ignore_thres\n",
        "        )\n",
        "\n",
        "        xc1, yc1, xc2, yc2 = self.smallestenclosing(pred_boxes[obj_mask], target_boxes[obj_mask])\n",
        "        c = ((xc2 - xc1) ** 2) + ((yc2 - yc1) ** 2) + 1e-7\n",
        "\n",
        "        d = (tx[obj_mask] - x[obj_mask]) ** 2 + (ty[obj_mask] - y[obj_mask]) ** 2\n",
        "\n",
        "        rDIoU = d/c\n",
        "\n",
        "        iou_masked = iou[obj_mask]\n",
        "        v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(tw[obj_mask]/th[obj_mask])-torch.atan(w[obj_mask]/h[obj_mask])), 2)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            S = 1 - iou_masked\n",
        "            alpha = v / (S + v + 1e-7)\n",
        "\n",
        "        CIoUloss = (1 - iou_masked + rDIoU + alpha * v).sum(0)/num_samples\n",
        "        loss_conf_obj = F.binary_cross_entropy(pred_conf[obj_mask], tconf[obj_mask])\n",
        "        loss_conf_noobj = F.binary_cross_entropy(pred_conf[noobj_mask], tconf[noobj_mask])\n",
        "        loss_conf = self.obj_scale * loss_conf_obj + self.noobj_scale * loss_conf_noobj\n",
        "        \n",
        "#         print(\"pred_cls[obj_mask]\",pred_cls[obj_mask])\n",
        "#         print(\"target=tcls[obj_mask]\",tcls[obj_mask])\n",
        "        loss_cls = F.binary_cross_entropy(input=pred_cls[obj_mask], target=tcls[obj_mask])\n",
        "        \n",
        "#         CIoUloss = 0\n",
        "#         loss_conf = 0\n",
        "#         print(\"CIoUloss\",CIoUloss)\n",
        "#         print(\"loss_cls\",loss_cls)\n",
        "#         print(\"loss_conf\",loss_conf)\n",
        "#         print(\"loss_conf_obj\",loss_conf_obj)\n",
        "#         print(\"loss_conf_noobj\",loss_conf_noobj)\n",
        "    \n",
        "        total_loss = CIoUloss + loss_cls + loss_conf\n",
        "\n",
        "        return output, total_loss, CIoUloss , loss_cls , loss_conf\n",
        "\n",
        "    def compute_grid_offsets(self, grid_size, cuda=True):\n",
        "        self.grid_size = grid_size\n",
        "        g = self.grid_size\n",
        "        FloatTensor = torch.cuda.FloatTensor if cuda else torch.FloatTensor\n",
        "        self.stride = self.img_dim / self.grid_size\n",
        "        # Calculate offsets for each grid\n",
        "        self.grid_x = torch.arange(g).repeat(g, 1).view([1, 1, g, g]).type(FloatTensor)    \n",
        "        self.grid_y = torch.arange(g).repeat(g, 1).t().view([1, 1, g, g]).type(FloatTensor)\n",
        "        self.scaled_anchors = FloatTensor([(a_w / self.stride, a_h / self.stride) for a_w, a_h in self.anchors])\n",
        "        self.anchor_w = self.scaled_anchors[:, 0:1].view((1, self.num_anchors, 1, 1)) \n",
        "        self.anchor_h = self.scaled_anchors[:, 1:2].view((1, self.num_anchors, 1, 1)) \n",
        "\n",
        "    def bbox_wh_iou(self, wh1, wh2):\n",
        "        wh2 = wh2.t()\n",
        "        w1, h1 = wh1[0], wh1[1]\n",
        "        w2, h2 = wh2[0], wh2[1]\n",
        "        inter_area = torch.min(w1, w2) * torch.min(h1, h2)\n",
        "        union_area = (w1 * h1 + 1e-16) + w2 * h2 - inter_area\n",
        "        return inter_area / union_area\n",
        "\n",
        "\n",
        "    def bbox_iou(self, box1, box2, x1y1x2y2=True, get_areas = False):\n",
        "        if not x1y1x2y2:\n",
        "            b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
        "            b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
        "            b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
        "            b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
        "        else:\n",
        "            b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "            b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "        inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "        inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "        inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "        inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "    \n",
        "        inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1, min=0) * torch.clamp(\n",
        "            inter_rect_y2 - inter_rect_y1, min=0\n",
        "        )\n",
        "\n",
        "        b1_area = (b1_x2 - b1_x1) * (b1_y2 - b1_y1)\n",
        "        b2_area = (b2_x2 - b2_x1) * (b2_y2 - b2_y1)\n",
        "        union_area = (b1_area + b2_area - inter_area + 1e-16)\n",
        "\n",
        "        if get_areas:\n",
        "            return inter_area, union_area\n",
        "\n",
        "        iou = inter_area / union_area\n",
        "        return iou\n",
        "\n",
        "\n",
        "    def smallestenclosing(self, pred_boxes, target_boxes):\n",
        "        targetxc = target_boxes[..., 0]\n",
        "        targetyc = target_boxes[..., 1]\n",
        "        targetwidth = target_boxes[..., 2]\n",
        "        targetheight = target_boxes[..., 3]\n",
        "\n",
        "        predxc = pred_boxes[..., 0]\n",
        "        predyc = pred_boxes[..., 1]\n",
        "        predwidth = pred_boxes[..., 2]\n",
        "        predheight = pred_boxes[..., 3]\n",
        "\n",
        "        xc1 = torch.min(predxc - (predwidth/2), targetxc - (targetwidth/2))\n",
        "        yc1 = torch.min(predyc - (predheight/2), targetyc - (targetheight/2))\n",
        "        xc2 = torch.max(predxc + (predwidth/2), targetxc + (targetwidth/2))\n",
        "        yc2 = torch.max(predyc + (predheight/2), targetyc + (targetheight/2))\n",
        "\n",
        "        return xc1, yc1, xc2, yc2\n",
        "\n",
        "    def xywh2xyxy(self, x):\n",
        "        y = torch.zeros_like(x) if isinstance(x, torch.Tensor) else np.zeros_like(x)\n",
        "        y[:, 0] = x[:, 0] - x[:, 2] / 2\n",
        "        y[:, 1] = x[:, 1] - x[:, 3] / 2\n",
        "        y[:, 2] = x[:, 0] + x[:, 2] / 2\n",
        "        y[:, 3] = x[:, 1] + x[:, 3] / 2\n",
        "        return y\n",
        "  \n",
        "  \n",
        "    def build_targets(self, pred_boxes, pred_cls, target, anchors, ignore_thres):\n",
        "        ByteTensor = torch.cuda.BoolTensor if pred_boxes.is_cuda else torch.BoolTensor\n",
        "        FloatTensor = torch.cuda.FloatTensor if pred_boxes.is_cuda else torch.FloatTensor\n",
        "\n",
        "        nB = pred_boxes.size(0)\n",
        "        nA = pred_boxes.size(1)\n",
        "        nC = pred_cls.size(-1)\n",
        "        nG = pred_boxes.size(2)\n",
        "\n",
        "        obj_mask = ByteTensor(nB, nA, nG, nG).fill_(0)\n",
        "        noobj_mask = ByteTensor(nB, nA, nG, nG).fill_(1)\n",
        "        class_mask = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        iou = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        tx = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        ty = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        tw = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        th = FloatTensor(nB, nA, nG, nG).fill_(0)\n",
        "        tcls = FloatTensor(nB, nA, nG, nG, nC).fill_(0)\n",
        "\n",
        "        target_boxes_grid = FloatTensor(nB, nA, nG, nG, 4).fill_(0)\n",
        "        \n",
        "        target_boxes = target[:, 2:6] * nG\n",
        "        gxy = target_boxes[:, :2]\n",
        "        gwh = target_boxes[:, 2:]\n",
        "\n",
        "        ious = torch.stack([self.bbox_wh_iou(anchor, gwh) for anchor in anchors])\n",
        "     \n",
        "        best_ious, best_n = ious.max(0)\n",
        "\n",
        "        b, target_labels = target[:, :2].long().t()\n",
        "        gx, gy = gxy.t()\n",
        "        gw, gh = gwh.t()\n",
        "        gi, gj = gxy.long().t()\n",
        "\n",
        "        target_boxes_grid[b, best_n, gj, gi] = target_boxes\n",
        "\n",
        "        obj_mask[b, best_n, gj, gi] = 1\n",
        "        noobj_mask[b, best_n, gj, gi] = 0\n",
        "\n",
        "        for i, anchor_ious in enumerate(ious.t()):\n",
        "            noobj_mask[b[i], anchor_ious > ignore_thres, gj[i], gi[i]] = 0\n",
        "\n",
        "        tx[b, best_n, gj, gi] = gx - gx.floor()\n",
        "        ty[b, best_n, gj, gi] = gy - gy.floor()\n",
        "\n",
        "        tw[b, best_n, gj, gi] = torch.log(gw / anchors[best_n][:, 0] + 1e-16)\n",
        "        th[b, best_n, gj, gi] = torch.log(gh / anchors[best_n][:, 1] + 1e-16)\n",
        "\n",
        "        tcls[b, best_n, gj, gi, target_labels] = 0.99\n",
        "\n",
        "        class_mask[b, best_n, gj, gi] = (pred_cls[b, best_n, gj, gi].argmax(-1) == target_labels).float()\n",
        "        iou[b, best_n, gj, gi] = self.bbox_iou(pred_boxes[b, best_n, gj, gi], target_boxes, x1y1x2y2=False)\n",
        "\n",
        "        tconf = obj_mask.float()\n",
        "\n",
        "        return iou, class_mask, obj_mask, noobj_mask, tx, ty, tw, th, tcls, tconf, target_boxes_grid\n",
        "\n",
        "\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iedpHCmNybKD"
      },
      "source": [
        "## YOLOV4 Model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4EunpU8r97U2"
      },
      "source": [
        "class YOLOv4(nn.Module):\n",
        "  def __init__(self,num_anchor=None, num_class=2,img_dim=608,anchors=None): \n",
        "    super(YOLOv4,self).__init__()\n",
        "    if anchors is None:\n",
        "        anchors = [[[ 58,  50]],\n",
        "                   [[159, 177]],\n",
        "                   [[285, 202]]]\n",
        "#       anchors = [[[10, 13], [16, 30], [33, 23]],\n",
        "#                  [[30, 61], [62, 45], [59, 119]],\n",
        "#                 [[116, 90], [156, 198], [373, 326]]]\n",
        "    self.img_dim = img_dim\n",
        "\n",
        "    num_anchor = len(anchors)\n",
        "    self.csp_darknet53   = CSPDarknet53()\n",
        "    self.neck            = Neck()\n",
        "\n",
        "#     self.yolo_head_large   = YOLO_head(512, 3, num_class)  #  def __init__(self, in_c, num_anchor, num_class):\n",
        "#     self.yolo_head_medium  = YOLO_head(256, 3, num_class)  \n",
        "#     self.yolo_head_small   = YOLO_head(128, 3 , num_class)  \n",
        "    \n",
        "    self.yolo_head_large   = YOLO_head(512, 1, num_class)  #  def __init__(self, in_c, num_anchor, num_class):\n",
        "    self.yolo_head_medium  = YOLO_head(256, 1, num_class)  \n",
        "    self.yolo_head_small   = YOLO_head(128, 1 , num_class)\n",
        "    \n",
        "    self.yolo_layer_large  = YOLO_Layer(anchors[2], num_class, img_dim) \n",
        "    self.yolo_layer_medium = YOLO_Layer(anchors[1], num_class, img_dim) \n",
        "    self.yolo_layer_small  = YOLO_Layer(anchors[0], num_class, img_dim)                   \n",
        "\n",
        "  def forward(self,x,targets):\n",
        "    x_s, x_m, x_l             = self.csp_darknet53(x) \n",
        "    backbone                  = [x_s,x_m,x_l]         \n",
        "    pan_x_s, pan_x_m, pan_x_l = self.neck(backbone) \n",
        "    yolo_head_l              = self.yolo_head_large(pan_x_l)  \n",
        "    yolo_head_m              = self.yolo_head_medium(pan_x_m) \n",
        "    yolo_head_s              = self.yolo_head_small(pan_x_s) \n",
        "\n",
        "    out_l , loss_l , CIoUloss_l , loss_cls_l , loss_conf_l  = self.yolo_layer_large (yolo_head_l,targets) \n",
        "    out_m , loss_m , CIoUloss_m , loss_cls_m , loss_conf_m  = self.yolo_layer_medium(yolo_head_m,targets)\n",
        "    out_s , loss_s , CIoUloss_s , loss_cls_s , loss_conf_s  = self.yolo_layer_small (yolo_head_s,targets)\n",
        "\n",
        "    out_l = out_l.detach()\n",
        "    out_m = out_m.detach()\n",
        "    out_s = out_s.detach()\n",
        "\n",
        "    final_out  = torch.cat((out_l, out_m, out_s), dim=1) # final_out Shape = [ Batch_size, Total_YOLO_anchors , 5+num_class ]\n",
        "    total_loss = (loss_l + loss_m + loss_s) / 3\n",
        "    CIoUloss   = (CIoUloss_l + CIoUloss_m + CIoUloss_s) / 3\n",
        "    loss_cls   = (loss_cls_l + loss_cls_m + loss_cls_s) / 3\n",
        "    loss_conf  = (loss_conf_l + loss_conf_m + loss_conf_s) / 3\n",
        "    \n",
        "#     return out_l,loss_l\n",
        "\n",
        "    return final_out, total_loss, CIoUloss, loss_cls, loss_conf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "apBgTKLe1IJV"
      },
      "source": [
        "## Model Object"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5I_HaUa51Hdw"
      },
      "source": [
        "img_dim  = 320\n",
        "img_size = 320\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bRtR5Y2gB11S"
      },
      "source": [
        "# model = YOLOv4(img_dim=416).to('cuda')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tmlz7H-RekRp"
      },
      "source": [
        "## Dataloader"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ci23YGZLen3O"
      },
      "source": [
        "import torch \n",
        "import torchvision\n",
        "from torch.utils.data import Dataset,DataLoader\n",
        "from torchvision import transforms\n",
        "from matplotlib import pyplot as plt\n",
        "from PIL import Image\n",
        "import glob2\n",
        "import numpy as np\n",
        "import albumentations as A \n",
        "from albumentations.pytorch import ToTensor\n",
        "import cv2\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XvTDMhtCt0sv"
      },
      "source": [
        "class yolo_image_dataset(Dataset):\n",
        "    def __init__(self,image_path,label_path, transform_albumentations):\n",
        "        super().__init__()\n",
        "        self.image_path = image_path\n",
        "        self.label_path = label_path\n",
        "        self.transform_albumentations  = transform_albumentations\n",
        "        self.imagelist        = glob2.glob(self.image_path+\"/*jpg\")\n",
        "\n",
        "    def __getitem__(self,index):\n",
        "        image_path  = self.imagelist[index]\n",
        "        image       = Image.open(image_path)\n",
        "        image_type = image.mode\n",
        "        \n",
        "        image_array = np.array(image)\n",
        "#         print(\"image_path\",image_path)\n",
        "        \n",
        "        if(image_type != 'RGB'):\n",
        "            im = image_array\n",
        "            w, h = im.shape\n",
        "            image_array = np.empty((w, h, 3), dtype=np.uint8)\n",
        "            image_array[:, :, 2] =  image_array[:, :, 1] =  image_array[:, :, 0] =  im\n",
        "\n",
        "        image_filename = image_path.split(\"/\")[-1]      \n",
        "        image_filename = image_filename.split(\".\")[0]  \n",
        "\n",
        "        label_path = self.label_path + \"/\" + image_filename + \".txt\"\n",
        "        label_file_list = open(label_path,'r').read().splitlines()  \n",
        "        albumentations_bbox = []  \n",
        "        category_ids = []\n",
        "        for line in label_file_list:\n",
        "            anno = line.split(\" \")\n",
        "            X , Y , W, H, class_id  = float(anno[1]),float(anno[2]),float(anno[3]),float(anno[4]) , int (anno[0])\n",
        "#             single_box = [ X , Y , W , H, class_id] \n",
        "            single_box = [min(X,0.995), min(Y,0.995), min(W,0.995) , min(H,0.995) , class_id]\n",
        "            albumentations_bbox.append(single_box)\n",
        "            category_ids.append(class_id )\n",
        "        \n",
        "        transformed_albumentations = self.transform_albumentations(image=image_array, bboxes=albumentations_bbox)\n",
        "        image = transformed_albumentations['image']   \n",
        "        bbox  = transformed_albumentations['bboxes'] \n",
        "        bbox_tensor = torch.tensor(bbox) \n",
        "        if len(bbox_tensor) > 0:\n",
        "            bbox_tensor = torch.index_select(bbox_tensor,1,torch.LongTensor([4,0,1,2,3])) \n",
        "        else:\n",
        "            target = torch.tensor([])\n",
        "            return image_path , image , target\n",
        "#             bbox_tensor = torch.zeros(1,5)  \n",
        "            \n",
        "        target = torch.zeros(len(bbox),6)\n",
        "        target[:,1:] = bbox_tensor\n",
        "\n",
        "        return  image_path , image , target   \n",
        "    \n",
        "    \n",
        "    def collate_fn(self,batch):   \n",
        "        img_paths , imgs , targets = list(zip(*batch)) \n",
        "        \n",
        "        i = 0\n",
        "        for target in targets:  #target for each image\n",
        "            # target= list of [img_id,class_id,X,Y,W,H] for each bbox in a given image \n",
        "            if len(target) > 0:  # No empty target , No tensor([])\n",
        "                target[:,0] = i  # Update img_id  \n",
        "            i = i+1\n",
        "                \n",
        "        targets = [boxes for boxes in targets if boxes is not None] #Remove empty bbox from target\n",
        "        target_tensor = torch.cat(targets, 0) \n",
        "\n",
        "        imgs = torch.stack([img for img in imgs])\n",
        "\n",
        "        return img_paths, imgs, target_tensor\n",
        "    \n",
        "        \n",
        "    def __len__(self): \n",
        "        total_images = len(self.imagelist)\n",
        "        return total_images"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SgjuE26lB11b"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z3O_s0ZmB11e"
      },
      "source": [
        "transform_albumentations = A.Compose([\n",
        "    A.SmallestMaxSize(max_size=img_size,interpolation=cv2.INTER_LINEAR) ,\n",
        "    A.RandomCrop(height=img_size, width=img_size),  \n",
        "#     A.Normalize(), \n",
        "    ToTensor() \n",
        "], bbox_params=A.BboxParams(format='yolo' )) \n",
        "\n",
        "test_dataset    = yolo_image_dataset(image_path='images/', label_path='labels/',transform_albumentations=transform_albumentations)\n",
        "test_dataloader = DataLoader(dataset=test_dataset, batch_size=32,num_workers=8 ,collate_fn=test_dataset.collate_fn, shuffle = True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NqnDyvC1FWOn"
      },
      "source": [
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSEjOJU7B11i",
        "outputId": "40a2344d-0016-43a0-863e-ca4b55645b5a"
      },
      "source": [
        "model_det = YOLOv4(img_dim=img_dim).to('cuda')\n",
        "model_det.load_state_dict(torch.load('model_classification_weight_only.pt'))\n",
        "\n",
        "\n",
        "EPOCHS = 200\n",
        "device = 'cuda'\n",
        "optimizer = torch.optim.SGD(model_det.parameters(),lr=0.002)  # 0001\n",
        "# optimizer = torch.optim.Adam(model_det.parameters(), lr=0.00000001)\n",
        "import time\n",
        "import copy\n",
        "from torch.autograd import Variable\n",
        "\n",
        "total_loss_list = []\n",
        "total_CIOU_list = []\n",
        "total_cls_list  = []\n",
        "total_conf_list  = []\n",
        "\n",
        "total_loss = 0\n",
        "total_CIOU = 0\n",
        "total_cls = 0\n",
        "total_cnf = 0\n",
        "loss = 1\n",
        "outputs = 1\n",
        "for epoch in range(EPOCHS):\n",
        "    del total_loss\n",
        "    del total_CIOU\n",
        "    del total_cls\n",
        "    del total_cnf\n",
        "    total_loss = 0\n",
        "    total_CIOU = 0\n",
        "    total_cls = 0\n",
        "    total_cnf = 0\n",
        "    num_iter   = 0 \n",
        "    model_det.train()\n",
        "    print(\"epoch\",epoch)\n",
        "    start_time = time.time()\n",
        "    for batch_i, (_, imgs, targets) in enumerate(test_dataloader):\n",
        "        batches_done = len(test_dataloader) * epoch + batch_i\n",
        "\n",
        "        imgs = Variable(imgs.to(device))\n",
        "        targets = Variable(targets.to(device), requires_grad=False)\n",
        "        del loss\n",
        "        del outputs\n",
        "        outputs, loss, CIoUloss, loss_cls, loss_conf = model_det(imgs, targets)\n",
        "#         print(\"[INFO] loss\",loss)\n",
        "#         loss = Variable(loss, requires_grad = True)\n",
        "        loss.backward()\n",
        "        \n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "        \n",
        "        total_loss = total_loss + copy.copy(loss.item() )\n",
        "        total_CIOU = total_CIOU + copy.copy(CIoUloss.item() )\n",
        "        total_cls  = total_cls + copy.copy(loss_cls.item() )\n",
        "        total_cnf  = total_cnf+ copy.copy(loss_conf.item() )\n",
        "        num_iter += 1\n",
        "        \n",
        "    if (epoch%15==0):\n",
        "        savename = './model_det'+str(epoch)+\".pth\"\n",
        "        torch.save(model_det, savename)   \n",
        "    print(\"Total Loss:{:.6f}    CIOULoss:{:.6f}    Cls_Loss:{:.6f}    Conf_Loss:{:.6f}\".format(total_loss/num_iter, total_CIOU/num_iter, total_cls/num_iter, total_cnf/num_iter))\n",
        "    total_loss_list.append(total_loss/num_iter)\n",
        "    total_CIOU_list.append(total_CIOU/num_iter)\n",
        "    total_cls_list.append(total_cls/num_iter)\n",
        "    total_conf_list.append(total_cnf/num_iter)\n",
        "#     total_loss.append(loss)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch 0\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type YOLOv4. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CSPDarknet53. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CBM. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Mish. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type first_CSP. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type ResNetUnit. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CSP. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type Neck. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CBLx3_1. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CBL. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type SPP. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CBLx3_2. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type FPN_Lateral_Connection. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type CBLx5. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type PAN_Lateral_Connection. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type YOLO_head. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n",
            "/root/anaconda3/envs/maulik_py38/lib/python3.8/site-packages/torch/serialization.py:359: UserWarning: Couldn't retrieve source code for container of type YOLO_Layer. It won't be checked for correctness upon loading.\n",
            "  warnings.warn(\"Couldn't retrieve source code for container of \"\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Total Loss:7.491199    CIOULoss:1.136956    Cls_Loss:0.380225    Conf_Loss:5.974018\n",
            "epoch 1\n",
            "Total Loss:6.121696    CIOULoss:1.026819    Cls_Loss:0.344227    Conf_Loss:4.750650\n",
            "epoch 2\n",
            "Total Loss:5.752954    CIOULoss:0.991110    Cls_Loss:0.296830    Conf_Loss:4.465014\n",
            "epoch 3\n",
            "Total Loss:5.386081    CIOULoss:0.976846    Cls_Loss:0.271326    Conf_Loss:4.137910\n",
            "epoch 4\n",
            "Total Loss:5.347071    CIOULoss:0.989361    Cls_Loss:0.300592    Conf_Loss:4.057118\n",
            "epoch 5\n",
            "Total Loss:5.205735    CIOULoss:0.973714    Cls_Loss:0.283189    Conf_Loss:3.948831\n",
            "epoch 6\n",
            "Total Loss:4.991511    CIOULoss:0.925032    Cls_Loss:0.260009    Conf_Loss:3.806470\n",
            "epoch 7\n",
            "Total Loss:4.957967    CIOULoss:0.936393    Cls_Loss:0.242898    Conf_Loss:3.778676\n",
            "epoch 8\n",
            "Total Loss:4.861213    CIOULoss:0.936864    Cls_Loss:0.228395    Conf_Loss:3.695954\n",
            "epoch 9\n",
            "Total Loss:4.800125    CIOULoss:0.941397    Cls_Loss:0.217450    Conf_Loss:3.641278\n",
            "epoch 10\n",
            "Total Loss:5.049667    CIOULoss:1.009699    Cls_Loss:0.253010    Conf_Loss:3.786958\n",
            "epoch 11\n",
            "Total Loss:4.909739    CIOULoss:1.046364    Cls_Loss:0.228775    Conf_Loss:3.634600\n",
            "epoch 12\n",
            "Total Loss:4.725236    CIOULoss:0.960156    Cls_Loss:0.213123    Conf_Loss:3.551957\n",
            "epoch 13\n",
            "Total Loss:4.855684    CIOULoss:0.946635    Cls_Loss:0.273912    Conf_Loss:3.635137\n",
            "epoch 14\n",
            "Total Loss:4.832537    CIOULoss:1.020932    Cls_Loss:0.246674    Conf_Loss:3.564931\n",
            "epoch 15\n",
            "Total Loss:4.610906    CIOULoss:0.980253    Cls_Loss:0.196447    Conf_Loss:3.434206\n",
            "epoch 16\n",
            "Total Loss:4.484355    CIOULoss:0.959169    Cls_Loss:0.186038    Conf_Loss:3.339147\n",
            "epoch 17\n",
            "Total Loss:4.557317    CIOULoss:0.959791    Cls_Loss:0.212843    Conf_Loss:3.384683\n",
            "epoch 18\n",
            "Total Loss:4.384778    CIOULoss:0.947587    Cls_Loss:0.171618    Conf_Loss:3.265573\n",
            "epoch 19\n",
            "Total Loss:4.370727    CIOULoss:0.946272    Cls_Loss:0.182471    Conf_Loss:3.241984\n",
            "epoch 20\n",
            "Total Loss:4.310494    CIOULoss:0.926008    Cls_Loss:0.183811    Conf_Loss:3.200674\n",
            "epoch 21\n",
            "Total Loss:4.265887    CIOULoss:0.909607    Cls_Loss:0.179736    Conf_Loss:3.176544\n",
            "epoch 22\n",
            "Total Loss:4.084664    CIOULoss:0.901301    Cls_Loss:0.151789    Conf_Loss:3.031574\n",
            "epoch 23\n",
            "Total Loss:4.046714    CIOULoss:0.906019    Cls_Loss:0.159757    Conf_Loss:2.980937\n",
            "epoch 24\n",
            "Total Loss:4.439682    CIOULoss:0.991636    Cls_Loss:0.202587    Conf_Loss:3.245459\n",
            "epoch 25\n",
            "Total Loss:4.060396    CIOULoss:0.933752    Cls_Loss:0.160955    Conf_Loss:2.965688\n",
            "epoch 26\n",
            "Total Loss:3.935840    CIOULoss:0.901596    Cls_Loss:0.154595    Conf_Loss:2.879649\n",
            "epoch 27\n",
            "Total Loss:3.879867    CIOULoss:0.960371    Cls_Loss:0.142683    Conf_Loss:2.776812\n",
            "epoch 28\n",
            "Total Loss:3.649267    CIOULoss:0.887544    Cls_Loss:0.129720    Conf_Loss:2.632003\n",
            "epoch 29\n",
            "Total Loss:3.570189    CIOULoss:0.876277    Cls_Loss:0.145919    Conf_Loss:2.547993\n",
            "epoch 30\n",
            "Total Loss:3.492710    CIOULoss:0.888575    Cls_Loss:0.123559    Conf_Loss:2.480576\n",
            "epoch 31\n",
            "Total Loss:3.341205    CIOULoss:0.847968    Cls_Loss:0.116677    Conf_Loss:2.376561\n",
            "epoch 32\n",
            "Total Loss:3.254556    CIOULoss:0.873524    Cls_Loss:0.116919    Conf_Loss:2.264112\n",
            "epoch 33\n",
            "Total Loss:3.195077    CIOULoss:0.821823    Cls_Loss:0.113164    Conf_Loss:2.260090\n",
            "epoch 34\n",
            "Total Loss:3.203551    CIOULoss:0.847812    Cls_Loss:0.119987    Conf_Loss:2.235752\n",
            "epoch 35\n",
            "Total Loss:3.003262    CIOULoss:0.817240    Cls_Loss:0.104627    Conf_Loss:2.081395\n",
            "epoch 36\n",
            "Total Loss:3.157978    CIOULoss:0.875783    Cls_Loss:0.106564    Conf_Loss:2.175632\n",
            "epoch 37\n",
            "Total Loss:3.074625    CIOULoss:0.839118    Cls_Loss:0.113011    Conf_Loss:2.122497\n",
            "epoch 38\n",
            "Total Loss:2.893171    CIOULoss:0.813008    Cls_Loss:0.104840    Conf_Loss:1.975322\n",
            "epoch 39\n",
            "Total Loss:2.777881    CIOULoss:0.817470    Cls_Loss:0.088774    Conf_Loss:1.871638\n",
            "epoch 40\n",
            "Total Loss:2.623292    CIOULoss:0.794192    Cls_Loss:0.081407    Conf_Loss:1.747693\n",
            "epoch 41\n",
            "Total Loss:2.625972    CIOULoss:0.813682    Cls_Loss:0.081627    Conf_Loss:1.730663\n",
            "epoch 42\n",
            "Total Loss:2.563635    CIOULoss:0.822499    Cls_Loss:0.079201    Conf_Loss:1.661935\n",
            "epoch 43\n",
            "Total Loss:2.483707    CIOULoss:0.787931    Cls_Loss:0.079239    Conf_Loss:1.616538\n",
            "epoch 44\n",
            "Total Loss:2.415564    CIOULoss:0.754138    Cls_Loss:0.074767    Conf_Loss:1.586659\n",
            "epoch 45\n",
            "Total Loss:2.401471    CIOULoss:0.799973    Cls_Loss:0.076986    Conf_Loss:1.524512\n",
            "epoch 46\n",
            "Total Loss:2.364401    CIOULoss:0.791178    Cls_Loss:0.079901    Conf_Loss:1.493322\n",
            "epoch 47\n",
            "Total Loss:2.300429    CIOULoss:0.765710    Cls_Loss:0.073433    Conf_Loss:1.461287\n",
            "epoch 48\n",
            "Total Loss:2.236008    CIOULoss:0.775035    Cls_Loss:0.067370    Conf_Loss:1.393603\n",
            "epoch 49\n",
            "Total Loss:2.286894    CIOULoss:0.805675    Cls_Loss:0.077054    Conf_Loss:1.404165\n",
            "epoch 50\n",
            "Total Loss:2.362236    CIOULoss:0.826499    Cls_Loss:0.094738    Conf_Loss:1.440999\n",
            "epoch 51\n",
            "Total Loss:3.073356    CIOULoss:0.876592    Cls_Loss:0.105373    Conf_Loss:2.091391\n",
            "epoch 52\n",
            "Total Loss:2.472902    CIOULoss:0.892002    Cls_Loss:0.083617    Conf_Loss:1.497283\n",
            "epoch 53\n",
            "Total Loss:2.349548    CIOULoss:0.853847    Cls_Loss:0.083847    Conf_Loss:1.411854\n",
            "epoch 54\n",
            "Total Loss:2.237052    CIOULoss:0.850268    Cls_Loss:0.068325    Conf_Loss:1.318458\n",
            "epoch 55\n",
            "Total Loss:2.139766    CIOULoss:0.826309    Cls_Loss:0.068590    Conf_Loss:1.244867\n",
            "epoch 56\n",
            "Total Loss:2.124867    CIOULoss:0.844439    Cls_Loss:0.062842    Conf_Loss:1.217585\n",
            "epoch 57\n",
            "Total Loss:2.065899    CIOULoss:0.815348    Cls_Loss:0.066582    Conf_Loss:1.183969\n",
            "epoch 58\n",
            "Total Loss:1.964054    CIOULoss:0.785527    Cls_Loss:0.057314    Conf_Loss:1.121213\n",
            "epoch 59\n",
            "Total Loss:1.961073    CIOULoss:0.812730    Cls_Loss:0.061856    Conf_Loss:1.086487\n",
            "epoch 60\n",
            "Total Loss:2.088614    CIOULoss:0.925825    Cls_Loss:0.066663    Conf_Loss:1.096126\n",
            "epoch 61\n",
            "Total Loss:2.060864    CIOULoss:0.887468    Cls_Loss:0.066801    Conf_Loss:1.106596\n",
            "epoch 62\n",
            "Total Loss:2.017763    CIOULoss:0.867705    Cls_Loss:0.057171    Conf_Loss:1.092888\n",
            "epoch 63\n",
            "Total Loss:1.989569    CIOULoss:0.856732    Cls_Loss:0.060520    Conf_Loss:1.072317\n",
            "epoch 64\n",
            "Total Loss:2.020819    CIOULoss:0.866561    Cls_Loss:0.058588    Conf_Loss:1.095670\n",
            "epoch 65\n",
            "Total Loss:1.961011    CIOULoss:0.873682    Cls_Loss:0.055993    Conf_Loss:1.031337\n",
            "epoch 66\n",
            "Total Loss:2.142329    CIOULoss:0.966588    Cls_Loss:0.063945    Conf_Loss:1.111796\n",
            "epoch 67\n",
            "Total Loss:2.161307    CIOULoss:0.932923    Cls_Loss:0.087086    Conf_Loss:1.141298\n",
            "epoch 68\n",
            "Total Loss:2.117851    CIOULoss:0.931210    Cls_Loss:0.074999    Conf_Loss:1.111641\n",
            "epoch 69\n",
            "Total Loss:2.009198    CIOULoss:0.920457    Cls_Loss:0.058253    Conf_Loss:1.030488\n",
            "epoch 70\n",
            "Total Loss:1.992382    CIOULoss:0.935924    Cls_Loss:0.058726    Conf_Loss:0.997732\n",
            "epoch 71\n",
            "Total Loss:3.491259    CIOULoss:1.002057    Cls_Loss:0.171822    Conf_Loss:2.317379\n",
            "epoch 72\n",
            "Total Loss:4.369130    CIOULoss:1.092067    Cls_Loss:0.221698    Conf_Loss:3.055365\n",
            "epoch 73\n",
            "Total Loss:3.383910    CIOULoss:1.147635    Cls_Loss:0.113540    Conf_Loss:2.122735\n",
            "epoch 74\n",
            "Total Loss:2.938950    CIOULoss:1.100022    Cls_Loss:0.106760    Conf_Loss:1.732169\n",
            "epoch 75\n",
            "Total Loss:2.648439    CIOULoss:1.022645    Cls_Loss:0.085026    Conf_Loss:1.540768\n",
            "epoch 76\n",
            "Total Loss:2.419841    CIOULoss:0.976703    Cls_Loss:0.072941    Conf_Loss:1.370198\n",
            "epoch 77\n",
            "Total Loss:2.275438    CIOULoss:0.976695    Cls_Loss:0.069735    Conf_Loss:1.229008\n",
            "epoch 78\n",
            "Total Loss:2.306629    CIOULoss:1.021335    Cls_Loss:0.072439    Conf_Loss:1.212856\n",
            "epoch 79\n",
            "Total Loss:2.337283    CIOULoss:1.088286    Cls_Loss:0.073185    Conf_Loss:1.175812\n",
            "epoch 80\n",
            "Total Loss:2.350144    CIOULoss:1.124710    Cls_Loss:0.067522    Conf_Loss:1.157912\n",
            "epoch 81\n",
            "Total Loss:2.281723    CIOULoss:1.064995    Cls_Loss:0.068180    Conf_Loss:1.148548\n",
            "epoch 82\n",
            "Total Loss:2.119467    CIOULoss:0.954086    Cls_Loss:0.056624    Conf_Loss:1.108758\n",
            "epoch 83\n",
            "Total Loss:2.065391    CIOULoss:0.995339    Cls_Loss:0.057871    Conf_Loss:1.012181\n",
            "epoch 84\n",
            "Total Loss:2.010031    CIOULoss:0.994081    Cls_Loss:0.058088    Conf_Loss:0.957862\n",
            "epoch 85\n",
            "Total Loss:1.928172    CIOULoss:0.938765    Cls_Loss:0.050303    Conf_Loss:0.939105\n",
            "epoch 86\n",
            "Total Loss:1.855817    CIOULoss:0.864369    Cls_Loss:0.054235    Conf_Loss:0.937212\n",
            "epoch 87\n",
            "Total Loss:1.789528    CIOULoss:0.846312    Cls_Loss:0.052050    Conf_Loss:0.891165\n",
            "epoch 88\n",
            "Total Loss:1.777037    CIOULoss:0.822619    Cls_Loss:0.046066    Conf_Loss:0.908352\n",
            "epoch 89\n",
            "Total Loss:1.648158    CIOULoss:0.772164    Cls_Loss:0.048916    Conf_Loss:0.827078\n",
            "epoch 90\n",
            "Total Loss:1.609310    CIOULoss:0.740646    Cls_Loss:0.048049    Conf_Loss:0.820615\n",
            "epoch 91\n",
            "Total Loss:1.573091    CIOULoss:0.765730    Cls_Loss:0.047204    Conf_Loss:0.760158\n",
            "epoch 92\n",
            "Total Loss:1.581172    CIOULoss:0.768886    Cls_Loss:0.044739    Conf_Loss:0.767547\n",
            "epoch 93\n",
            "Total Loss:1.621090    CIOULoss:0.779579    Cls_Loss:0.048697    Conf_Loss:0.792814\n",
            "epoch 94\n",
            "Total Loss:1.622129    CIOULoss:0.802145    Cls_Loss:0.051109    Conf_Loss:0.768875\n",
            "epoch 95\n",
            "Total Loss:1.658673    CIOULoss:0.854191    Cls_Loss:0.046719    Conf_Loss:0.757763\n",
            "epoch 96\n",
            "Total Loss:1.596520    CIOULoss:0.815559    Cls_Loss:0.051411    Conf_Loss:0.729550\n",
            "epoch 97\n",
            "Total Loss:1.538705    CIOULoss:0.769057    Cls_Loss:0.045387    Conf_Loss:0.724261\n",
            "epoch 98\n",
            "Total Loss:1.588426    CIOULoss:0.782609    Cls_Loss:0.051648    Conf_Loss:0.754170\n",
            "epoch 99\n",
            "Total Loss:1.647542    CIOULoss:0.798608    Cls_Loss:0.054478    Conf_Loss:0.794456\n",
            "epoch 100\n",
            "Total Loss:1.746344    CIOULoss:0.833013    Cls_Loss:0.078527    Conf_Loss:0.834803\n",
            "epoch 101\n",
            "Total Loss:1.665309    CIOULoss:0.811914    Cls_Loss:0.060213    Conf_Loss:0.793183\n",
            "epoch 102\n",
            "Total Loss:1.614153    CIOULoss:0.803793    Cls_Loss:0.049313    Conf_Loss:0.761047\n",
            "epoch 103\n",
            "Total Loss:1.527608    CIOULoss:0.762305    Cls_Loss:0.045071    Conf_Loss:0.720232\n",
            "epoch 104\n",
            "Total Loss:1.605967    CIOULoss:0.840848    Cls_Loss:0.047441    Conf_Loss:0.717677\n",
            "epoch 105\n",
            "Total Loss:1.520247    CIOULoss:0.786831    Cls_Loss:0.046039    Conf_Loss:0.687377\n",
            "epoch 106\n",
            "Total Loss:1.461325    CIOULoss:0.778634    Cls_Loss:0.043845    Conf_Loss:0.638846\n",
            "epoch 107\n",
            "Total Loss:1.400930    CIOULoss:0.763800    Cls_Loss:0.041994    Conf_Loss:0.595136\n",
            "epoch 108\n",
            "Total Loss:1.428232    CIOULoss:0.758633    Cls_Loss:0.045330    Conf_Loss:0.624269\n",
            "epoch 109\n",
            "Total Loss:1.453259    CIOULoss:0.761735    Cls_Loss:0.040656    Conf_Loss:0.650868\n",
            "epoch 110\n",
            "Total Loss:1.446379    CIOULoss:0.772411    Cls_Loss:0.042978    Conf_Loss:0.630989\n",
            "epoch 111\n",
            "Total Loss:1.432913    CIOULoss:0.779863    Cls_Loss:0.043472    Conf_Loss:0.609577\n",
            "epoch 112\n",
            "Total Loss:1.457608    CIOULoss:0.774406    Cls_Loss:0.039841    Conf_Loss:0.643361\n",
            "epoch 113\n",
            "Total Loss:1.353949    CIOULoss:0.734923    Cls_Loss:0.038122    Conf_Loss:0.580905\n",
            "epoch 114\n",
            "Total Loss:1.350150    CIOULoss:0.724295    Cls_Loss:0.041470    Conf_Loss:0.584385\n",
            "epoch 115\n",
            "Total Loss:1.359950    CIOULoss:0.686639    Cls_Loss:0.042266    Conf_Loss:0.631045\n",
            "epoch 116\n",
            "Total Loss:1.398060    CIOULoss:0.707600    Cls_Loss:0.043457    Conf_Loss:0.647004\n",
            "epoch 117\n",
            "Total Loss:1.392512    CIOULoss:0.719536    Cls_Loss:0.044196    Conf_Loss:0.628780\n",
            "epoch 118\n",
            "Total Loss:1.351481    CIOULoss:0.752679    Cls_Loss:0.039471    Conf_Loss:0.559330\n",
            "epoch 119\n",
            "Total Loss:1.368296    CIOULoss:0.763049    Cls_Loss:0.039525    Conf_Loss:0.565722\n",
            "epoch 120\n",
            "Total Loss:1.298090    CIOULoss:0.717563    Cls_Loss:0.038123    Conf_Loss:0.542404\n",
            "epoch 121\n",
            "Total Loss:1.271155    CIOULoss:0.709474    Cls_Loss:0.038960    Conf_Loss:0.522721\n",
            "epoch 122\n",
            "Total Loss:1.303627    CIOULoss:0.743880    Cls_Loss:0.038437    Conf_Loss:0.521310\n",
            "epoch 123\n",
            "Total Loss:1.369308    CIOULoss:0.793195    Cls_Loss:0.042117    Conf_Loss:0.533995\n",
            "epoch 124\n",
            "Total Loss:1.343759    CIOULoss:0.763478    Cls_Loss:0.041188    Conf_Loss:0.539093\n",
            "epoch 125\n",
            "Total Loss:1.346472    CIOULoss:0.760000    Cls_Loss:0.036881    Conf_Loss:0.549591\n",
            "epoch 126\n",
            "Total Loss:1.379882    CIOULoss:0.797423    Cls_Loss:0.041437    Conf_Loss:0.541022\n",
            "epoch 127\n",
            "Total Loss:1.393138    CIOULoss:0.816605    Cls_Loss:0.039156    Conf_Loss:0.537377\n",
            "epoch 128\n",
            "Total Loss:1.510905    CIOULoss:0.886635    Cls_Loss:0.044358    Conf_Loss:0.579913\n",
            "epoch 129\n",
            "Total Loss:1.507461    CIOULoss:0.926940    Cls_Loss:0.041744    Conf_Loss:0.538777\n",
            "epoch 130\n",
            "Total Loss:1.490664    CIOULoss:0.925957    Cls_Loss:0.044711    Conf_Loss:0.519996\n",
            "epoch 131\n",
            "Total Loss:2.125343    CIOULoss:1.061240    Cls_Loss:0.059841    Conf_Loss:1.004263\n",
            "epoch 132\n",
            "Total Loss:1.742861    CIOULoss:1.036885    Cls_Loss:0.042141    Conf_Loss:0.663835\n",
            "epoch 133\n",
            "Total Loss:1.526578    CIOULoss:0.902759    Cls_Loss:0.040248    Conf_Loss:0.583571\n",
            "epoch 134\n",
            "Total Loss:1.512558    CIOULoss:0.854154    Cls_Loss:0.066555    Conf_Loss:0.591849\n",
            "epoch 135\n",
            "Total Loss:1.454675    CIOULoss:0.853845    Cls_Loss:0.045884    Conf_Loss:0.554946\n",
            "epoch 136\n",
            "Total Loss:1.392565    CIOULoss:0.824297    Cls_Loss:0.041352    Conf_Loss:0.526916\n",
            "epoch 137\n",
            "Total Loss:1.364214    CIOULoss:0.822547    Cls_Loss:0.039123    Conf_Loss:0.502543\n",
            "epoch 138\n",
            "Total Loss:1.293154    CIOULoss:0.746292    Cls_Loss:0.039826    Conf_Loss:0.507036\n",
            "epoch 139\n",
            "Total Loss:1.244326    CIOULoss:0.716983    Cls_Loss:0.038511    Conf_Loss:0.488833\n",
            "epoch 140\n",
            "Total Loss:1.280867    CIOULoss:0.750788    Cls_Loss:0.041681    Conf_Loss:0.488398\n",
            "epoch 141\n",
            "Total Loss:1.342195    CIOULoss:0.790825    Cls_Loss:0.045499    Conf_Loss:0.505870\n",
            "epoch 142\n",
            "Total Loss:1.311511    CIOULoss:0.796115    Cls_Loss:0.042228    Conf_Loss:0.473169\n",
            "epoch 143\n",
            "Total Loss:1.245966    CIOULoss:0.739616    Cls_Loss:0.041971    Conf_Loss:0.464379\n",
            "epoch 144\n",
            "Total Loss:1.218279    CIOULoss:0.708852    Cls_Loss:0.037703    Conf_Loss:0.471724\n",
            "epoch 145\n",
            "Total Loss:1.205440    CIOULoss:0.714294    Cls_Loss:0.037463    Conf_Loss:0.453683\n",
            "epoch 146\n",
            "Total Loss:1.346554    CIOULoss:0.741822    Cls_Loss:0.040967    Conf_Loss:0.563766\n",
            "epoch 147\n",
            "Total Loss:1.352086    CIOULoss:0.785280    Cls_Loss:0.044942    Conf_Loss:0.521864\n",
            "epoch 148\n",
            "Total Loss:1.290727    CIOULoss:0.750318    Cls_Loss:0.040488    Conf_Loss:0.499921\n",
            "epoch 149\n",
            "Total Loss:1.246604    CIOULoss:0.753093    Cls_Loss:0.040640    Conf_Loss:0.452871\n",
            "epoch 150\n",
            "Total Loss:1.223183    CIOULoss:0.736046    Cls_Loss:0.036450    Conf_Loss:0.450687\n",
            "epoch 151\n",
            "Total Loss:1.227776    CIOULoss:0.733704    Cls_Loss:0.036572    Conf_Loss:0.457500\n",
            "epoch 152\n",
            "Total Loss:1.249549    CIOULoss:0.742355    Cls_Loss:0.040304    Conf_Loss:0.466889\n",
            "epoch 153\n",
            "Total Loss:1.274889    CIOULoss:0.768042    Cls_Loss:0.038936    Conf_Loss:0.467911\n",
            "epoch 154\n",
            "Total Loss:1.248664    CIOULoss:0.743884    Cls_Loss:0.042097    Conf_Loss:0.462682\n",
            "epoch 155\n",
            "Total Loss:1.208851    CIOULoss:0.738923    Cls_Loss:0.038959    Conf_Loss:0.430969\n",
            "epoch 156\n",
            "Total Loss:1.192633    CIOULoss:0.718011    Cls_Loss:0.041076    Conf_Loss:0.433546\n",
            "epoch 157\n",
            "Total Loss:1.212861    CIOULoss:0.727540    Cls_Loss:0.040817    Conf_Loss:0.444505\n",
            "epoch 158\n",
            "Total Loss:1.226721    CIOULoss:0.767704    Cls_Loss:0.038233    Conf_Loss:0.420785\n",
            "epoch 159\n",
            "Total Loss:1.233722    CIOULoss:0.784164    Cls_Loss:0.041905    Conf_Loss:0.407653\n",
            "epoch 160\n",
            "Total Loss:1.226895    CIOULoss:0.760645    Cls_Loss:0.042019    Conf_Loss:0.424231\n",
            "epoch 161\n",
            "Total Loss:1.255680    CIOULoss:0.754496    Cls_Loss:0.040594    Conf_Loss:0.460590\n",
            "epoch 162\n",
            "Total Loss:1.313751    CIOULoss:0.765633    Cls_Loss:0.043444    Conf_Loss:0.504673\n",
            "epoch 163\n",
            "Total Loss:1.242311    CIOULoss:0.730534    Cls_Loss:0.043350    Conf_Loss:0.468427\n",
            "epoch 164\n",
            "Total Loss:1.577171    CIOULoss:0.843836    Cls_Loss:0.050653    Conf_Loss:0.682681\n",
            "epoch 165\n",
            "Total Loss:1.358743    CIOULoss:0.804347    Cls_Loss:0.041854    Conf_Loss:0.512542\n",
            "epoch 166\n",
            "Total Loss:1.222351    CIOULoss:0.729422    Cls_Loss:0.039434    Conf_Loss:0.453495\n",
            "epoch 167\n",
            "Total Loss:1.229872    CIOULoss:0.730386    Cls_Loss:0.038722    Conf_Loss:0.460764\n",
            "epoch 168\n",
            "Total Loss:1.241291    CIOULoss:0.754492    Cls_Loss:0.038487    Conf_Loss:0.448312\n",
            "epoch 169\n",
            "Total Loss:1.217114    CIOULoss:0.746223    Cls_Loss:0.037692    Conf_Loss:0.433199\n",
            "epoch 170\n",
            "Total Loss:1.141388    CIOULoss:0.684992    Cls_Loss:0.040911    Conf_Loss:0.415485\n",
            "epoch 171\n",
            "Total Loss:1.154290    CIOULoss:0.710068    Cls_Loss:0.040422    Conf_Loss:0.403799\n",
            "epoch 172\n",
            "Total Loss:1.216782    CIOULoss:0.780961    Cls_Loss:0.037392    Conf_Loss:0.398429\n",
            "epoch 173\n",
            "Total Loss:1.179797    CIOULoss:0.744714    Cls_Loss:0.037207    Conf_Loss:0.397876\n",
            "epoch 174\n",
            "Total Loss:1.190691    CIOULoss:0.748775    Cls_Loss:0.035265    Conf_Loss:0.406650\n",
            "epoch 175\n",
            "Total Loss:1.178927    CIOULoss:0.744035    Cls_Loss:0.036547    Conf_Loss:0.398344\n",
            "epoch 176\n",
            "Total Loss:1.156203    CIOULoss:0.734046    Cls_Loss:0.035096    Conf_Loss:0.387061\n",
            "epoch 177\n",
            "Total Loss:1.291793    CIOULoss:0.823682    Cls_Loss:0.041746    Conf_Loss:0.426364\n",
            "epoch 178\n",
            "Total Loss:1.338044    CIOULoss:0.857533    Cls_Loss:0.042506    Conf_Loss:0.438005\n",
            "epoch 179\n",
            "Total Loss:1.285347    CIOULoss:0.808433    Cls_Loss:0.042346    Conf_Loss:0.434568\n",
            "epoch 180\n",
            "Total Loss:1.278254    CIOULoss:0.812092    Cls_Loss:0.039194    Conf_Loss:0.426968\n",
            "epoch 181\n",
            "Total Loss:1.406520    CIOULoss:0.837841    Cls_Loss:0.045790    Conf_Loss:0.522888\n",
            "epoch 182\n",
            "Total Loss:1.311309    CIOULoss:0.812775    Cls_Loss:0.041652    Conf_Loss:0.456881\n",
            "epoch 183\n",
            "Total Loss:1.314540    CIOULoss:0.854670    Cls_Loss:0.038071    Conf_Loss:0.421799\n",
            "epoch 184\n",
            "Total Loss:1.319547    CIOULoss:0.870832    Cls_Loss:0.039086    Conf_Loss:0.409629\n",
            "epoch 185\n",
            "Total Loss:1.364226    CIOULoss:0.903511    Cls_Loss:0.037913    Conf_Loss:0.422802\n",
            "epoch 186\n",
            "Total Loss:1.491327    CIOULoss:1.032992    Cls_Loss:0.035725    Conf_Loss:0.422609\n",
            "epoch 187\n",
            "Total Loss:1.448010    CIOULoss:1.015322    Cls_Loss:0.041765    Conf_Loss:0.390924\n",
            "epoch 188\n",
            "Total Loss:1.419314    CIOULoss:1.000920    Cls_Loss:0.035722    Conf_Loss:0.382673\n",
            "epoch 189\n",
            "Total Loss:1.325449    CIOULoss:0.916628    Cls_Loss:0.035500    Conf_Loss:0.373321\n",
            "epoch 190\n",
            "Total Loss:1.196177    CIOULoss:0.786573    Cls_Loss:0.036038    Conf_Loss:0.373566\n",
            "epoch 191\n",
            "Total Loss:1.182094    CIOULoss:0.764313    Cls_Loss:0.036350    Conf_Loss:0.381431\n",
            "epoch 192\n",
            "Total Loss:1.152888    CIOULoss:0.735513    Cls_Loss:0.036459    Conf_Loss:0.380915\n",
            "epoch 193\n",
            "Total Loss:1.084637    CIOULoss:0.688668    Cls_Loss:0.033804    Conf_Loss:0.362165\n",
            "epoch 194\n",
            "Total Loss:1.135527    CIOULoss:0.711975    Cls_Loss:0.037606    Conf_Loss:0.385946\n",
            "epoch 195\n",
            "Total Loss:1.155422    CIOULoss:0.751683    Cls_Loss:0.039323    Conf_Loss:0.364416\n",
            "epoch 196\n",
            "Total Loss:1.159604    CIOULoss:0.769647    Cls_Loss:0.036027    Conf_Loss:0.353929\n",
            "epoch 197\n",
            "Total Loss:1.213867    CIOULoss:0.726118    Cls_Loss:0.039808    Conf_Loss:0.447942\n",
            "epoch 198\n",
            "Total Loss:1.144500    CIOULoss:0.701077    Cls_Loss:0.035894    Conf_Loss:0.407528\n",
            "epoch 199\n",
            "Total Loss:1.091154    CIOULoss:0.663699    Cls_Loss:0.037399    Conf_Loss:0.390056\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TJrAE6w9B11w"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eitshP1lB11y"
      },
      "source": [
        "torch.save(model_det.state_dict(), './final.pth')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6w5ASwxeB110"
      },
      "source": [
        "torch.save(model_det, './final.pt')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1KaH_4cwB12A"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QCuXVSPxiKE7"
      },
      "source": [
        "## loss Graph"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nZ5mTPZKiJLM",
        "outputId": "48bec1eb-bd4a-4481-bf37-a25deb0c495a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 295
        }
      },
      "source": [
        "import pickle\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "total_CIOU = pickle.load( open( \"total_CIOU_list.pkl\", \"rb\" ) )\n",
        "total_cls  = pickle.load( open( \"total_cls_list.pkl\" , \"rb\" ) )\n",
        "total_conf = pickle.load( open( \"total_conf_list.pkl\", \"rb\" ) )\n",
        "total_loss = pickle.load( open( \"total_loss_list.pkl\", \"rb\" ) )\n",
        "\n",
        "X = list(range(120))\n",
        "plt.plot(X, total_CIOU[:120], label = \"total_CIOU\")\n",
        "plt.plot(X, total_cls[:120] , label = \"total_cls\")\n",
        "plt.plot(X, total_conf[:120], label = \"total_conf\")\n",
        "plt.plot(X, total_loss[:120], label = \"total_loss\")\n",
        "plt.legend()\n",
        "\n",
        "plt.title('Loss vs Epoch')\n",
        "plt.xlabel('Epoch')\n",
        "plt.ylabel('Loss Value')\n",
        "\n",
        "plt.savefig(\"lossvsepoch.png\")\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C65cHyZ7iQwT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}
